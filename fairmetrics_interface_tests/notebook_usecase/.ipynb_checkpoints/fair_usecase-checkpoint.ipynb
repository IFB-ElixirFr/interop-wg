{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import argparse\n",
    "# import os, sys\n",
    "# sys.path.append(os.path.abspath('..'))\n",
    "# import test_metric\n",
    "\n",
    "import json\n",
    "import requests\n",
    "\n",
    "import rdflib\n",
    "from rdflib import ConjunctiveGraph\n",
    "from rdflib.compare import to_isomorphic, graph_diff\n",
    "import pyshacl\n",
    "\n",
    "import extruct\n",
    "from extruct.jsonld import JsonLdExtractor\n",
    "\n",
    "import re\n",
    "\n",
    "# DOI regex\n",
    "regex = r\"10.\\d{4,9}\\/[-._;()\\/:A-Z0-9]+\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of URIs to be tested\n",
    "# http://lod.openaire.eu/documentation \n",
    "\n",
    "input_URIs = ['https://data.inra.fr/dataset.xhtml?persistentId=doi:10.15454/TKMGCQ', \n",
    "    'https://doi.org/10.5281/zenodo.1147435',\n",
    "    'https://data.inra.fr/dataset.xhtml?persistentId=doi:10.15454/5K9HCS', \n",
    "    'https://search.datacite.org/works/10.7892/boris.108387', \n",
    "    'https://doi.org/10.6084/m9.figshare.c.3607916_d7.v1', \n",
    "    'https://search.datacite.org/works/10.6084/m9.figshare.c.3607916_d7.v1', \n",
    "    'https://api.datacite.org/dois/application/ld+json/10.6084/m9.figshare.c.3607916_d7.v1', \n",
    "    'https://bio.tools/rsat_peak-motifs',\n",
    "    'https://workflowhub.eu/workflows/18', \n",
    "    'https://tess.elixir-europe.org/materials/train-the-trainer', \n",
    "    'https://fairsharing.org/FAIRsharing.ZPRtfG', \n",
    "    'https://www.ebi.ac.uk/ols/ontologies/ncit/terms?iri=http%3A%2F%2Fpurl.obolibrary.org%2Fobo%2FNCIT_C2985', \n",
    "    'https://biit.cs.ut.ee/gprofiler/page/apis', \n",
    "    'https://bioportal.bioontology.org/ontologies/OCRE', \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input of URIs by type\n",
    "\n",
    "input_data = [\n",
    "    \"https://data.inra.fr/dataset.xhtml?persistentId=doi:10.15454/TKMGCQ\", # dataset INRA Dataverse\n",
    "    \"https://doi.pangaea.de/10.1594/PANGAEA.914331\", # dataset in PANGAEA\n",
    "]\n",
    "\n",
    "input_software = [\n",
    "    \"https://zenodo.org/record/3349821#.Xp7m9SNR2Uk\", # VM image in zenodo\n",
    "    \"https://explore.openaire.eu/search/software?softwareId=r37b0ad08687::275ecd99e516ed1b863e2a7586063a64\", # same VM image in OpenAir\n",
    "    \"https://data.inra.fr/dataset.xhtml?persistentId=doi:10.15454/5K9HCS\", # code in INRA Dataverse\n",
    "    \"https://bio.tools/rsat_peak-motifs\", # Tool in biotools\n",
    "    \"https://workflowhub.eu/workflows/18\", # Workflow in WorkflowHub\n",
    "    \"http://tara-oceans.mio.osupytheas.fr/ocean-gene-atlas/\", # OGA Main page of webtool\n",
    "]\n",
    "\n",
    "input_database = [\n",
    "    \"https://fairsharing.org/FAIRsharing.ZPRtfG\", # knowledge base in FAIRsharing (AgroLD)\n",
    "    \"http://remap.univ-amu.fr\" # Database of transcriptional regulators\n",
    "]\n",
    "\n",
    "input_ontology = [\n",
    "    \"https://bioportal.bioontology.org/ontologies/OCRE\", # Ontology in bioportal\n",
    "    \"https://www.ebi.ac.uk/ols/ontologies/ncit/terms?iri=http%3A%2F%2Fpurl.obolibrary.org%2Fobo%2FNCIT_C2985\" # OLS entry\n",
    "]\n",
    "\n",
    "input_publication = [\n",
    "    \"https://doi.org/10.1145/1614320.1614332\", # Paper from lod.openair\n",
    "    \"https://search.datacite.org/works/10.7892/boris.108387\", # Publication in Datacite\n",
    "    \"https://doi.org/10.6084/m9.figshare.c.3607916_d7.v1\", # Publication figure in FigShare\n",
    "    \"https://search.datacite.org/works/10.6084/m9.figshare.c.3607916_d7.v1\", # Publication figure in Datacite (same as previous)\n",
    "    \"https://api.datacite.org/dois/application/ld+json/10.6084/m9.figshare.c.3607916_d7.v1\" # Publication figure with Datacite API\n",
    "]\n",
    "\n",
    "input_training = [\n",
    "    \"https://tess.elixir-europe.org/materials/train-the-trainer\", # Training material in TeSS\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Retrieving of RDF linked-data in web pages\n",
    "\n",
    "# for URI in input_URIs:\n",
    "# for URI in input_training:\n",
    "# for URI in input_publication:\n",
    "# for URI in input_ontology:\n",
    "# for URI in input_database:\n",
    "def getKG(URI):\n",
    "    print(\"Retrieve KG for URI: \" + URI)\n",
    "    page = requests.get(URI)\n",
    "    html = page.content\n",
    "    d = extruct.extract(html, syntaxes=['microdata', 'rdfa', 'json-ld'], errors='ignore')\n",
    "    #print(json.dumps(d, indent=2))\n",
    "    kg = ConjunctiveGraph()\n",
    "    kg.parse(data = json.dumps(d['json-ld']), format=\"json-ld\")\n",
    "    kg.parse(data = json.dumps(d['rdfa']), format=\"json-ld\")\n",
    "    kg.parse(data = json.dumps(d['microdata']), format=\"json-ld\")\n",
    "    print(kg.serialize(format=\"turtle\").decode())\n",
    "    #break\n",
    "    print(len(kg))\n",
    "    return kg\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Augmenting embedded semantic annotation from multiple sources\n",
    "1. for each ressource find all typed or identified entities \n",
    "2. for each entity: retrieve their semantic description based on other SPARQL endpoints. 'DESCRIBE queries' \n",
    "   - datacite sparql endpoint\n",
    "   - sameAs.cc sparql endpoint\n",
    "   - BioPortal sparql endpoint\n",
    "   - OpenAire sparql endpoint\n",
    "   - PubMed sparql endpoint (http://linkedlifedata.com/sparql)\n",
    "   - DBPedia\n",
    "   - WikiData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrieve entities of specific types\n",
    "\n",
    "from SPARQLWrapper import SPARQLWrapper, N3, JSON, RDF, TURTLE, JSONLD\n",
    "from rdflib import Graph, Namespace\n",
    "from rdflib.namespace import RDF\n",
    "\n",
    "schema = Namespace(\"http://schema.org/\")\n",
    "\n",
    "#sparql_endpoints = ['http://linkedlifedata.com/sparql', 'http://lod.openaire.eu/sparql']\n",
    "#sparql_endpoints = ['http://lod.openaire.eu/sparql', 'http://sparql.bioontology.org/ontologies/sparql']\n",
    "sparql_endpoints = [\n",
    "                    'http://sparql.wikipathways.org/sparql',\n",
    "                    #'https://opencitations.net/sparql',\n",
    "                    'http://lod.openaire.eu/sparql', \n",
    "                    'https://dbpedia.org/sparql', \n",
    "                    #'https://bio2rdf.org/sparql',\n",
    "                    #'https://sparql.uniprot.org/sparql',\n",
    "                    'https://www.ebi.ac.uk/rdf/services/sparql',\n",
    "                    #'https://query.wikidata.org/sparql',\n",
    "                    'http://www.scholarlydata.org/sparql',\n",
    "                    'https://io.datascience-paris-saclay.fr/sparql',\n",
    "                    'https://opendata1.opendata.u-psud.fr/sparql',\n",
    "                    'http://data.bnf.fr/sparql',\n",
    "                    #'http://sparql.wikipathways.org/',\n",
    "                    'https://sparql.orthodb.org/sparql',\n",
    "                    'https://data.idref.fr/sparql',\n",
    "                    #'https://go3.opendata.u-psud.fr/sparql',\n",
    "                    #'http://data.persee.fr/explorer/sparql-endpoint/',\n",
    "                   ]\n",
    "\n",
    "def retrieve_entities(G):\n",
    "    entities = []\n",
    "    for s, p, o in G.triples((None, RDF.type, None)):\n",
    "        #print(f'{s} - {p} - {o}')\n",
    "        print(str(o))\n",
    "        if type(s) != rdflib.term.BNode: entities.append(str(s))\n",
    "    for s, p, o in G.triples((None, schema.identifier, None)):\n",
    "        #print(f'identifier: {s} - {p} - {o}')\n",
    "        if type(o) != rdflib.term.BNode: entities.append(str(o))\n",
    "    for s, p, o in G.triples((None, schema.sameAs, None)):\n",
    "        #print(f'sameAs: {s} - {p} - {o}')\n",
    "        if type(o) != rdflib.term.BNode: entities.append(str(o))\n",
    "    for s, p, o in G.triples((None, schema.url, None)):\n",
    "        #print(f'url: {s} - {p} - {o}')\n",
    "        if type(o) != rdflib.term.BNode: entities.append(str(o))\n",
    "            \n",
    "    for s, p, o in G.triples((None, schema.license, None)):\n",
    "        #print(f'url: {s} - {p} - {o}')\n",
    "        if type(o) != rdflib.term.BNode: entities.append(str(o))\n",
    "    for s, p, o in G.triples((None, schema.distribution, None)):\n",
    "        #print(f'url: {s} - {p} - {o}')\n",
    "        if type(o) != rdflib.term.BNode: entities.append(str(o))\n",
    "    for s, p, o in G.triples((None, schema.citation, None)):\n",
    "        #print(f'url: {s} - {p} - {o}')\n",
    "        if type(o) != rdflib.term.BNode: entities.append(str(o))\n",
    "    for s, p, o in G.triples((None, schema.provider, None)):\n",
    "        #print(f'url: {s} - {p} - {o}')\n",
    "        if type(o) != rdflib.term.BNode: entities.append(str(o))\n",
    "        #if type(o) != rdflib.term.URIRef: entities.append(str(o))\n",
    "            \n",
    "    #for s, p, o in G.triples((None, None, None)):\n",
    "        #print(type(o))\n",
    "        #print(f'Schema: {s} - {p} - {o}')\n",
    "        #if type(o) != rdflib.term.BNode: entities.append(str(o))\n",
    "    return entities\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Describe lod.openaire\n",
    "def describe_loa(uri, g):\n",
    "    #g = Graph()\n",
    "    print(f'SPARQL for [ {uri} ] with enpoint [ LOA ]')\n",
    "    sparql = SPARQLWrapper(\"http://lod.openaire.eu/sparql\")\n",
    "    sparql.setQuery(\"\"\"\n",
    "            DESCRIBE ?x WHERE {   \n",
    "            ?x <http://lod.openaire.eu/vocab/resPersistentID> '\"\"\" + uri + \"\"\"' \n",
    "            }\n",
    "    \"\"\")\n",
    "\n",
    "    g_len = Graph()\n",
    "    sparql.setReturnFormat(N3)\n",
    "    results = sparql.query().convert()\n",
    "    print(\"Results: \" + str(len(g_len.parse(data=results, format=\"n3\"))))\n",
    "    g.parse(data=results, format=\"n3\")\n",
    "    \n",
    "    #print(g.serialize(format='turtle').decode())\n",
    "    return g\n",
    "    \n",
    "#describe_loa(\"10.1145/1614320.1614332\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Describe datacite\n",
    "def describe_opencitation(uri, g):\n",
    "    #g = Graph()\n",
    "    print(f'SPARQL for [ {uri} ] with enpoint [ Opencitation ]')\n",
    "    sparql = SPARQLWrapper(\"https://opencitations.net/sparql\")\n",
    "    sparql.setQuery(\"\"\"\n",
    "            PREFIX cito: <http://purl.org/spar/cito/>\n",
    "            PREFIX dcterms: <http://purl.org/dc/terms/>\n",
    "            PREFIX datacite: <http://purl.org/spar/datacite/>\n",
    "            PREFIX literal: <http://www.essepuntato.it/2010/06/literalreification/>\n",
    "            PREFIX biro: <http://purl.org/spar/biro/>\n",
    "            PREFIX frbr: <http://purl.org/vocab/frbr/core#>\n",
    "            PREFIX c4o: <http://purl.org/spar/c4o/>\n",
    "            \n",
    "            DESCRIBE ?x WHERE {\n",
    "                ?x datacite:hasIdentifier/literal:hasLiteralValue '\"\"\" + uri + \"\"\"' \n",
    "            }\n",
    "    \"\"\")\n",
    "\n",
    "    sparql.setReturnFormat(TURTLE)\n",
    "    results = sparql.query().convert()\n",
    "    print(\"Results: \" + str(len(results)))\n",
    "    \n",
    "    results = results.serialize(format='turtle').decode()\n",
    "    \n",
    "    g.parse(data=results, format=\"turtle\")\n",
    "    \n",
    "    #print(g.serialize(format='turtle').decode())\n",
    "    return g\n",
    "\n",
    "#describe_opencitation(\"10.1186/1471-2105-11-244\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Describe Wikidata\n",
    "\n",
    "def describe_wikidata(uri, g):\n",
    "    #g = Graph()\n",
    "    print(f'SPARQL for [ {uri} ] with enpoint [ Wikidata ]')\n",
    "    sparql = SPARQLWrapper(\"https://query.wikidata.org/sparql\")\n",
    "    sparql.setQuery(\"\"\"\n",
    "            PREFIX wd: <http://www.wikidata.org/entity/>\n",
    "            PREFIX wdt: <http://www.wikidata.org/prop/direct/>\n",
    "            PREFIX wikibase: <http://wikiba.se/ontology#>\n",
    "            PREFIX p: <http://www.wikidata.org/prop/>\n",
    "            PREFIX ps: <http://www.wikidata.org/prop/statement/>\n",
    "            PREFIX pq: <http://www.wikidata.org/prop/qualifier/>\n",
    "            PREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#>\n",
    "            PREFIX bd: <http://www.bigdata.com/rdf#>\n",
    "            \n",
    "            DESCRIBE ?x WHERE {   \n",
    "                ?x wdt:P356 '10.6084/M9.FIGSHARE.4539889' \n",
    "            }\n",
    "    \"\"\")\n",
    "\n",
    "    sparql.setReturnFormat(N3)\n",
    "    results = sparql.query().convert()\n",
    "    print(\"Results: \" + str(len(results)))\n",
    "    results = results.serialize(format='turtle').decode()\n",
    "    \n",
    "    g.parse(data=results, format=\"n3\")\n",
    "    \n",
    "    #print(g.serialize(format='turtle').decode())\n",
    "    return g\n",
    "\n",
    "#describe_wikidata(\"10.6084/M9.FIGSHARE.4539889\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieve KG for URI: https://doi.org/10.1145/1614320.1614332\n",
      "\n",
      "\n",
      "0\n",
      "\n",
      "\n",
      "Retrieve KG for URI: https://search.datacite.org/works/10.7892/boris.108387\n",
      "@prefix ns1: <http://schema.org/> .\n",
      "@prefix ns2: <http://www.w3.org/1999/xhtml/vocab#> .\n",
      "\n",
      "<https://doi.org/10.7892/boris.108387> a ns1:ScholarlyArticle ;\n",
      "    ns1:author [ a ns1:Person ;\n",
      "            ns1:familyName \"Klink\" ;\n",
      "            ns1:givenName \"Thorsten\" ;\n",
      "            ns1:name \"Thorsten Klink\" ],\n",
      "        [ a ns1:Person ;\n",
      "            ns1:familyName \"Bonel\" ;\n",
      "            ns1:givenName \"Harald Marcel\" ;\n",
      "            ns1:name \"Harald Marcel Bonel\" ],\n",
      "        [ a ns1:Person ;\n",
      "            ns1:familyName \"Sprecher\" ;\n",
      "            ns1:givenName \"Marco\" ;\n",
      "            ns1:name \"Marco Sprecher\" ],\n",
      "        [ a ns1:Person ;\n",
      "            ns1:familyName \"Adler\" ;\n",
      "            ns1:givenName \"Sabine\" ;\n",
      "            ns1:name \"Sabine Adler\" ],\n",
      "        [ a ns1:Person ;\n",
      "            ns1:familyName \"Wermelinger\" ;\n",
      "            ns1:givenName \"Felix\" ;\n",
      "            ns1:name \"Felix Wermelinger\" ],\n",
      "        [ a ns1:Person ;\n",
      "            ns1:familyName \"Villiger\" ;\n",
      "            ns1:givenName \"Peter M\" ;\n",
      "            ns1:name \"Peter M Villiger\" ] ;\n",
      "    ns1:datePublished \"2017\"^^ns1:Date ;\n",
      "    ns1:description \"OBJECTIVE To evaluate contrast-enhanced magnetic resonance angiography (MRA) in diagnosis of inflammatory aortic involvement in patients with clinical suspicion of large-vessel vasculitis. PATIENTS AND METHODS Seventy-five patients, mean age 62 years (range 16-82 years), 44 female and 31 male, underwent gadolinium-enhanced MRA and were evaluated retrospectively. Thoracic MRA was performed in 32 patients, abdominal MRA in 7 patients and both thoracic and abdominal MRA in 36 patients. Temporal arterial biopsies were obtained from 22/75 patients. MRA positivity was defined as increased aortic wall signal in late gadolinium-enhanced axial turbo inversion recovery magnitude (TIRM) series. The influence of prior glucocorticoid intake on MRA outcome was evaluated. RESULTS MRA was positive in 24/75 patients, with lesions located in the thorax in 7 patients, the abdomen in 5 and in both thorax and abdomen in 12. Probability for positive MRA after glucocorticoid intake for more than 5 days before MRA was reduced by 89.3%. Histology was negative in 3/10 MRA-positive patients and positive in 5/12 MRA-negative patients. All 5/12 histology positive / MRA-negative patients had glucocorticoids for &gt;5 days prior to MRA and were diagnosed as having vasculitis. Positive predictive value for MRA was 92%, negative predictive value was 88%. CONCLUSIONS Contrast-enhanced MRA reliably identifies large vessel vasculitis. Vasculitic signals in MRA are very sensitive to glucocorticoids, suggesting that MRA should be done before glucocorticoid treatment.\" ;\n",
      "    ns1:encodingFormat \"application/pdf\" ;\n",
      "    ns1:identifier [ a ns1:PropertyValue ;\n",
      "            ns1:propertyID \"DOI\" ;\n",
      "            ns1:value \"https://doi.org/10.7892/boris.108387\" ] ;\n",
      "    ns1:inLanguage \"eng\" ;\n",
      "    ns1:keywords \"610 Medicine &amp; health\" ;\n",
      "    ns1:name \"Diagnostic value of contrast-enhanced magnetic resonance angiography in large-vessel vasculitis.\" ;\n",
      "    ns1:provider [ a ns1:Organization ;\n",
      "            ns1:name \"DataCite\" ] ;\n",
      "    ns1:publisher [ a ns1:Organization ;\n",
      "            ns1:name \"EMH Schweizerischer Ärzteverlag\" ] ;\n",
      "    ns1:url <https://boris.unibe.ch/108387/> .\n",
      "\n",
      "[] ns2:role ns2:navigation .\n",
      "\n",
      "\n",
      "49\n",
      "http://schema.org/Person\n",
      "http://schema.org/PropertyValue\n",
      "http://schema.org/Person\n",
      "http://schema.org/Organization\n",
      "http://schema.org/Organization\n",
      "http://schema.org/ScholarlyArticle\n",
      "http://schema.org/Person\n",
      "http://schema.org/Person\n",
      "http://schema.org/Person\n",
      "http://schema.org/Person\n",
      "DOI: True\n",
      "SPARQL for [ 10.7892/boris.108387 ] with enpoint [ LOA ]\n",
      "Results: 28\n",
      "SPARQL for [ 10.7892/boris.108387 ] with enpoint [ Opencitation ]\n",
      "Results: 0\n",
      "SPARQL for [ 10.7892/boris.108387 ] with enpoint [ Wikidata ]\n"
     ]
    }
   ],
   "source": [
    "#  interogate SPARQL endpoints for supplementary data\n",
    "def describe(uri):\n",
    "    g = Graph()\n",
    "\n",
    "    for endpoint in sparql_endpoints:\n",
    "        print(f'SPARQL for [ {uri} ] with enpoint [ {endpoint} ]')\n",
    "        sparql = SPARQLWrapper(endpoint)\n",
    "        sparql.setQuery(\"\"\"\n",
    "                DESCRIBE <\"\"\"+uri+\"\"\">\n",
    "            \"\"\")\n",
    "\n",
    "        sparql.setReturnFormat(N3)\n",
    "        results = sparql.query().convert()\n",
    "        g.parse(data=results, format=\"n3\")\n",
    "    \n",
    "    return g\n",
    "\n",
    "def isDOI(uri):\n",
    "    return bool(re.search(regex, uri, re.MULTILINE | re.IGNORECASE))\n",
    "\n",
    "def getDOI(uri):\n",
    "    match = re.search(regex, uri, re.MULTILINE | re.IGNORECASE)\n",
    "    return match.group(0)\n",
    "\n",
    "def compareGraph(g1, g2):\n",
    "    iso1 = to_isomorphic(g1)\n",
    "    iso2 = to_isomorphic(g2)\n",
    "\n",
    "    iso1 == iso2\n",
    "\n",
    "    in_both, in_first, in_second = graph_diff(iso1, iso2)\n",
    "    print(in_both.serialize(format='turtle').decode())\n",
    "\n",
    "for URI in input_publication:\n",
    "    kg = getKG(URI)\n",
    "    entities = retrieve_entities(kg)\n",
    "    augmented_kg = Graph()\n",
    "    for uri in entities:\n",
    "        # test DOI if one is found\n",
    "        print(\"DOI: \" + str(isDOI(uri)))\n",
    "        if isDOI(uri): \n",
    "            uri = getDOI(uri)\n",
    "            # describe on lod.openair\n",
    "        augmented_kg = describe_loa(uri, augmented_kg)\n",
    "        augmented_kg = describe_opencitation(uri, augmented_kg)\n",
    "        augmented_kg = describe_wikidata(uri, augmented_kg)\n",
    "        \n",
    "        #augmented_kg = describe(uri)\n",
    "        print(f'Augmented KG len: {len(augmented_kg)}')\n",
    "        print(augmented_kg.serialize(format='turtle').decode())\n",
    "        #print(augmented_kg.serialize(format='turtle').decode())\n",
    "        \n",
    "    # compare two graph\n",
    "    compareGraph(kg, augmented_kg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@prefix ns1: <http://example.org/ns#> .\n",
      "\n",
      "<http://example.org> ns1:rel [ ns1:label \"Same\" ],\n",
      "        <http://example.org/same> .\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Test Diff\n",
    "from rdflib.compare import to_isomorphic, graph_diff\n",
    "\n",
    "g1 = Graph().parse(format='n3', data='''\n",
    "    @prefix : <http://example.org/ns#> .\n",
    "    <http://example.org> :rel\n",
    "        <http://example.org/same>,\n",
    "        [ :label \"Same\" ],\n",
    "        <http://example.org/a>,\n",
    "        [ :label \"A\" ] .\n",
    "''')\n",
    "\n",
    "g2 = Graph().parse(format='n3', data='''\n",
    "    @prefix : <http://example.org/ns#> .\n",
    "    <http://example.org> :rel\n",
    "        <http://example.org/same>,\n",
    "        [ :label \"Same\" ],\n",
    "        <http://example.org/b>,\n",
    "        [ :label \"B\" ] .\n",
    "''')\n",
    "\n",
    "iso1 = to_isomorphic(g1)\n",
    "iso2 = to_isomorphic(g2)\n",
    "\n",
    "iso1 == iso2\n",
    "\n",
    "in_both, in_first, in_second = graph_diff(iso1, iso2)\n",
    "\n",
    "print(in_both.serialize(format='turtle').decode())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exemple constraint Graph\n",
    "\n",
    "str_ttl_constraint = \"\"\"@prefix dash: <http://datashapes.org/dash#> .\n",
    "@prefix rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#> .\n",
    "@prefix rdfs: <http://www.w3.org/2000/01/rdf-schema#> .\n",
    "@prefix schema: <http://schema.org/> .\n",
    "@prefix sh: <http://www.w3.org/ns/shacl#> .\n",
    "@prefix xsd: <http://www.w3.org/2001/XMLSchema#> .\n",
    "\n",
    "schema:DataCatalogShape\n",
    "    a sh:NodeShape ;\n",
    "    sh:targetClass schema:DataCatalog ;\n",
    "    sh:property [\n",
    "        sh:path schema:name ;\n",
    "        sh:datatype xsd:string ;\n",
    "        sh:name \"given name\" ;\n",
    "    ] ;\n",
    "    sh:property [\n",
    "        sh:path schema:description ;\n",
    "        sh:maxCount 1 ;\n",
    "    ] ;\n",
    "    sh:property [\n",
    "        sh:path schema:url ;\n",
    "    ] .\n",
    "\"\"\"\n",
    "\n",
    "shacl_graph = rdflib.ConjunctiveGraph()\n",
    "print(str_ttl_constraint)\n",
    "result = shacl_graph.parse(data=str_ttl_constraint, format='turtle')\n",
    "print(len(shacl_graph))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example data Graph\n",
    "data_graph_str = \"\"\"\n",
    "    {\n",
    "        \"@context\": \"http://schema.org\",\n",
    "        \"@type\": \"DataCatalog\",\n",
    "        \"identifier\":\"https://identifiers.org/MIR:00000364\",\n",
    "        \"name\": \"FAIRsharing.org\",\n",
    "        \"description\": \"A manually curated, informative and educational resource on data and metadata standards, inter-related to databases/data repositories and funder and journal publisher data policies from across disciplines. FAIRsharing is an ELIXIR-UK node resource and has an active role in the RDA and Force11 data initiatives.\",\n",
    "        \"url\": \"https://fairsharing.org/\",\n",
    "        \"dataset\": [\n",
    "            {\n",
    "                \"@type\" : \"Dataset\",\n",
    "                \"name\" : \"Metadata Standard\",\n",
    "                \"description\" : \"A manually curated registry of standards, split into three types - Terminology Artifacts (ontologies, e.g. Gene Ontology), Models and Formats (conceptual schema, formats, data models, e.g. FASTA), and Reporting Guidelines (e.g. the ARRIVE guidelines for in vivo animal testing). These are linked to the databases that implement them and the funder and journal publisher data policies that recommend or endorse their use.\",\n",
    "                \"identifier\": \"https://www.fairsharing.org/bsg-sXXXXXX\",\n",
    "                \"url\" : \"https://fairsharing.org/standards\",\n",
    "                \"keywords\" : \"Standards, Metadata, Formats, Ontologies, Terminology Artifacts, Reporting Guidelines\",\n",
    "                \"includedInDataCatalog\" : \"https://www.fairsharing.org\"\n",
    "            },\n",
    "            {\n",
    "                \"@type\" : \"Dataset\",\n",
    "                \"name\" : \"Database\",\n",
    "                \"description\": \"A manually curated registry of databases/data repositories, conforming to the BioDBcore standard (from the Life Sciences). These are linked to the standards that they use and the funder and journal publisher data policies that recommend or endorse their use.\",\n",
    "                \"identifier\": \"https://www.fairsharing.org/bsg-dXXXXXX\",\n",
    "                \"url\": \"https://fairsharing.org/databases\",\n",
    "                \"keywords\": \"Database, Data repository\",\n",
    "                \"includedInDataCatalog\" : \"https://www.fairsharing.org\"\n",
    "            },\n",
    "            {\n",
    "                \"@type\" : \"Dataset\",\n",
    "                \"name\" : \"Data Policy\",\n",
    "                \"description\": \"A manually curated registry of data policies from research funders, journal publishers, societies, and other organisations. These are linked to the databases and standards that they recommend for use\",\n",
    "                \"identifier\": \"https://www.fairsharing.org/bsg-pXXXXXX\",\n",
    "                \"url\": \"https://fairsharing.org/policies\",\n",
    "                \"keywords\": \"Data policy, journal, funder, society\"\n",
    "            }\n",
    "            ],\n",
    "        \"keywords\": \"registry, life science, natural science, social science, \",\n",
    "        \"provider\":\n",
    "            [\n",
    "            {\n",
    "            \"@type\":\"Person\",\n",
    "            \"name\": \"FAIRsharing.org support\",\n",
    "            \"email\": \"contact@fairsharing.org\"\n",
    "            },\n",
    "            {\n",
    "            \"@type\":\"Organization\",\n",
    "            \"name\": \"Oxford e-Research Centre, University of Oxford\",\n",
    "            \"url\": \"http://www.oerc.ox.ac.uk/\"\n",
    "            },\n",
    "            {\n",
    "            \"@type\":\"Organization\",\n",
    "            \"name\": \"ELIXIR-UK\",\n",
    "            \"url\": \"http://www.elixir-uk.org\"\n",
    "            },\n",
    "            {\n",
    "            \"alternateName\": [\"FAIRsharing.org Registry\", \"BioSharing.org\"]\n",
    "            }\n",
    "            ],\n",
    "        \"license\": {\n",
    "            \"@type\": \"CreativeWork\",\n",
    "            \"name\": \"Creative Commons CC BY-SA 4.0 Attribution\",\n",
    "            \"url\": \"https://creativecommons.org/licenses/by-sa/4.0/\"\n",
    "            },\n",
    "        \"publication\":[\n",
    "            {\n",
    "                \"@type\":\"PublicationEvent\",\n",
    "                \"name\": \"BioSharing: curated and crowd-sourced metadata standards, databases and data policies in the life sciences.\",\n",
    "                \"url\": \"https://academic.oup.com/database/article-lookup/doi/10.1093/database/baw075\"\n",
    "            }\n",
    "        ]\n",
    "\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "data_graph = rdflib.ConjunctiveGraph()\n",
    "result = data_graph.parse(data=data_graph_str, format='json-ld')\n",
    "print(len(data_graph))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exemple SHACL test\n",
    "\n",
    "r = pyshacl.validate(data_graph = data_graph, \n",
    "             data_graph_format='json-ld', \n",
    "             shacl_graph = shacl_graph, \n",
    "             #shacl_graph = my_shacl_constraint,\n",
    "             shacl_graph_format = 'turtle', \n",
    "             ont_graph = None, \n",
    "             inference = 'rdfs', \n",
    "             abort_on_error = False, \n",
    "             meta_shacl = False, \n",
    "             debug = True)\n",
    "\n",
    "conforms, results_graph, results_text = r\n",
    "\n",
    "print(conforms)\n",
    "print(results_graph)\n",
    "print(results_text)\n",
    "\n",
    "report_query = \"\"\"\n",
    "    SELECT ?node ?path WHERE {\n",
    "        ?v rdf:type sh:ValidationReport ;\n",
    "           sh:result ?r .\n",
    "        ?r sh:focusNode ?node ;\n",
    "           sh:sourceShape ?s . \n",
    "        ?s sh:path ?path . \n",
    "    }\n",
    "\"\"\"\n",
    "\n",
    "results = results_graph.query(report_query)\n",
    "\n",
    "for r in results :\n",
    "    print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FAIRMetrics API execution\n",
    "\n",
    "data = b'{\"subject\": \"10.5281/zenodo.1147435\"}'\n",
    "r = requests.request(method=\"POST\", url='https://w3id.org/FAIR_Tests/tests/gen2_unique_identifier', data=data)\n",
    "\n",
    "print(json.dumps(r.json(), indent=2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
